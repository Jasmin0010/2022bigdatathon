{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_size = 500\n",
    "epochs = 2\n",
    "mini_batch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74357 entries, 0 to 74356\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   MBTI    74357 non-null  object\n",
      " 1   words   74357 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"MBTI_train.csv\", names=[\"MBTI\", \"words\"])\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INTP</td>\n",
       "      <td>say process model list like subscriber channel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>upon much manipulate retail finish like sacrif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>fit yes certain bff social feel goal go know n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>complete love within someone ideal joke solvea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>public strictly thing person x question person...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MBTI                                              words\n",
       "0  INTP  say process model list like subscriber channel...\n",
       "1  INFJ  upon much manipulate retail finish like sacrif...\n",
       "2  INFJ  fit yes certain bff social feel goal go know n...\n",
       "3  INTJ  complete love within someone ideal joke solvea...\n",
       "4  ENTJ  public strictly thing person x question person..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_test = df_train.drop(df_train.index).copy()\n",
    "df_val = df_val_test.sample(frac=0.5, random_state=5).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = df_train['MBTI'].values\n",
    "data_train = df_train['words'].values\n",
    "\n",
    "labels_val = df_val['MBTI'].values\n",
    "data_val = df_val['words'].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "en_labels_train = le.fit_transform(labels_train)\n",
    "en_labels_val = le.transform(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Count of types')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_labels, count = np.unique(df_train['MBTI'], return_counts=True)\n",
    "fig = plt.figure(figsize=(9,5))\n",
    "plt.bar(unique_labels, count, width=0.8)\n",
    "plt.title(\"Count of types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_data(tokenizer, data2pad, maxlen):\n",
    "    sequence = tokenizer.texts_to_sequences(data2pad)\n",
    "    paded = pad_sequences(sequence, truncating='post', padding='post', maxlen=maxlen)\n",
    "    return paded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paded_data_train = pad_data(tokenizer, data_train, txt_size)\n",
    "paded_data_val = pad_data(tokenizer, data_val, txt_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74357, 500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paded_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label): \n",
    "    text = tf.expand_dims(text, -1) \n",
    "    return vectorize_layer(text), label \n",
    "# Vectorize the data. \n",
    "\n",
    "max_features = 10000\n",
    "sequence_length = 500\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features, \n",
    "    output_mode=\"int\", \n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "vectorize_layer.adapt(data_train)\n",
    "vect_train = vectorize_layer(data_train)\n",
    "vect_val = vectorize_layer(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model1(post_size, num_labels):\n",
    "    model = Sequential([\n",
    "        layers.Embedding(10000, 32, input_length=post_size),\n",
    "        layers.Bidirectional(layers.LSTM(40, return_sequences=True)),\n",
    "        layers.Bidirectional(layers.LSTM(40)),\n",
    "        layers.Dense(num_labels, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model2(post_size, num_labels):\n",
    "    inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "    \n",
    "    x = layers.Embedding(10000, 128)(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "    x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    predictions = layers.Dense(num_labels, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "    model = tf.keras.Model(inputs, predictions)\n",
    "    return model\n",
    "\n",
    "def show_history(h):\n",
    "    epochs_trained = len(h.history['loss'])\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('accuracy'), label='Training')\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('val_accuracy'), label='Validation')\n",
    "    plt.ylim([0., 1.])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('loss'), label='Training')\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('val_loss'), label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 128)         1280000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 128)         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 128)         114816    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 128)         114816    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 16)                2064      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,528,208\n",
      "Trainable params: 1,528,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2_token = create_model2(txt_size, len(unique_labels))\n",
    "model2_token.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2_token.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2324/2324 [==============================] - ETA: 0s - loss: 1.6179 - accuracy: 0.4867WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "2324/2324 [==============================] - 440s 188ms/step - loss: 1.6179 - accuracy: 0.4867\n",
      "Epoch 2/2\n",
      "2324/2324 [==============================] - ETA: 0s - loss: 1.1303 - accuracy: 0.6628WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "2324/2324 [==============================] - 368s 158ms/step - loss: 1.1303 - accuracy: 0.6628\n"
     ]
    }
   ],
   "source": [
    "h2_token = model2_token.fit(\n",
    "    paded_data_train, en_labels_train,\n",
    "    validation_data = (paded_data_val, en_labels_val),\n",
    "    epochs = epochs,\n",
    "    #batch_size = mini_batch,\n",
    "    callbacks=[\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9337 entries, 0 to 9336\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   MBTI    0 non-null      object\n",
      " 1   words   9337 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 146.0+ KB\n"
     ]
    }
   ],
   "source": [
    "text_batch = data_val\n",
    "label_batch = data_val\n",
    "##text_batch, label_batch = data_val.as_numpy_iterator().next()\n",
    "\n",
    "df_test = pd.read_csv(\"MBTI_test.csv\", names=[\"words\"])\n",
    "df_test['MBTI'] = np.nan\n",
    "df_test = df_test[['MBTI', 'words']]\n",
    "df_test = df_test.astype({'MBTI':'object'})\n",
    "df_test.info()\n",
    "\n",
    "labels_test = df_test['MBTI'].values\n",
    "data_test = df_test['words'].values\n",
    "##en_labels_test = le.transform(labels_test)\n",
    "paded_data_test = pad_data(tokenizer, data_test, txt_size)\n",
    "vect_test = vectorize_layer(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = model2_token.predict_on_batch(vect_test)\n",
    "##df_test['MBTI'] = inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENFJ</th>\n",
       "      <th>ENFP</th>\n",
       "      <th>ENTJ</th>\n",
       "      <th>ENTP</th>\n",
       "      <th>ESFJ</th>\n",
       "      <th>ESFP</th>\n",
       "      <th>ESTJ</th>\n",
       "      <th>ESTP</th>\n",
       "      <th>INFJ</th>\n",
       "      <th>INFP</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>INTP</th>\n",
       "      <th>ISFJ</th>\n",
       "      <th>ISFP</th>\n",
       "      <th>ISTJ</th>\n",
       "      <th>ISTP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.518537</td>\n",
       "      <td>0.989429</td>\n",
       "      <td>0.072004</td>\n",
       "      <td>0.066087</td>\n",
       "      <td>0.006665</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>1.952052e-04</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.697332</td>\n",
       "      <td>0.780481</td>\n",
       "      <td>0.119343</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>0.058952</td>\n",
       "      <td>0.150026</td>\n",
       "      <td>0.098208</td>\n",
       "      <td>0.005113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.153921</td>\n",
       "      <td>0.094294</td>\n",
       "      <td>0.287124</td>\n",
       "      <td>0.995333</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>1.101356e-04</td>\n",
       "      <td>0.029807</td>\n",
       "      <td>0.781314</td>\n",
       "      <td>0.278508</td>\n",
       "      <td>0.384041</td>\n",
       "      <td>0.600946</td>\n",
       "      <td>0.030973</td>\n",
       "      <td>0.026916</td>\n",
       "      <td>0.035131</td>\n",
       "      <td>0.070328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028955</td>\n",
       "      <td>0.952374</td>\n",
       "      <td>0.745793</td>\n",
       "      <td>0.395842</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>5.260671e-07</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.315601</td>\n",
       "      <td>0.233377</td>\n",
       "      <td>0.997885</td>\n",
       "      <td>0.508927</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.152442</td>\n",
       "      <td>0.027656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.543518</td>\n",
       "      <td>0.875947</td>\n",
       "      <td>0.658192</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>1.299200e-08</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.363087</td>\n",
       "      <td>0.161309</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.970863</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.262920</td>\n",
       "      <td>0.078813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090935</td>\n",
       "      <td>0.058578</td>\n",
       "      <td>0.739373</td>\n",
       "      <td>0.600214</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>4.480776e-05</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.129361</td>\n",
       "      <td>0.391241</td>\n",
       "      <td>0.996780</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.163630</td>\n",
       "      <td>0.702166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ENFJ      ENFP      ENTJ      ENTP      ESFJ      ESFP          ESTJ  \\\n",
       "0  0.518537  0.989429  0.072004  0.066087  0.006665  0.025757  1.952052e-04   \n",
       "1  0.153921  0.094294  0.287124  0.995333  0.000529  0.004937  1.101356e-04   \n",
       "2  0.028955  0.952374  0.745793  0.395842  0.000196  0.001102  5.260671e-07   \n",
       "3  0.007937  0.543518  0.875947  0.658192  0.000013  0.000069  1.299200e-08   \n",
       "4  0.090935  0.058578  0.739373  0.600214  0.001548  0.000593  4.480776e-05   \n",
       "\n",
       "       ESTP      INFJ      INFP      INTJ      INTP      ISFJ      ISFP  \\\n",
       "0  0.000047  0.697332  0.780481  0.119343  0.013228  0.058952  0.150026   \n",
       "1  0.029807  0.781314  0.278508  0.384041  0.600946  0.030973  0.026916   \n",
       "2  0.000202  0.315601  0.233377  0.997885  0.508927  0.000259  0.001736   \n",
       "3  0.000313  0.363087  0.161309  0.999893  0.970863  0.000051  0.000093   \n",
       "4  0.009818  0.129361  0.391241  0.996780  0.999143  0.000492  0.004174   \n",
       "\n",
       "       ISTJ      ISTP  \n",
       "0  0.098208  0.005113  \n",
       "1  0.035131  0.070328  \n",
       "2  0.152442  0.027656  \n",
       "3  0.262920  0.078813  \n",
       "4  0.163630  0.702166  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##df_test.info()\n",
    "resultDF = pd.DataFrame(inference)\n",
    "resultDF.columns = unique_labels\n",
    "resultDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.989429\n",
       "1    0.995333\n",
       "2    0.997885\n",
       "3    0.999893\n",
       "4    0.999143\n",
       "dtype: float32"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##for i in resultDF:\n",
    "    ##result = pd.DataFrame([resultDF[i].argmax()])\n",
    "\n",
    "result = resultDF.max(axis=1)\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ENFP\n",
       "1    ENTP\n",
       "2    INTJ\n",
       "3    INTJ\n",
       "4    INTP\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##for i in result:\n",
    "  ##  idx_s = resultDF.idxmax([i])\n",
    "##idx_s = result.idxmax()\n",
    "\n",
    "##idx_s\n",
    "##index_value = []\n",
    "##index_value(max(result))\n",
    "\n",
    "result = resultDF.idxmax(axis=1)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'obj'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25676/3954396935.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0minference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'obj'"
     ]
    }
   ],
   "source": [
    "##inference.obj.str.strip()\n",
    "##inference.obj.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##for i in inference:\n",
    "##    inference[i].obj.str.isupper()\n",
    "##    while True:\n",
    "##        inference[i].obj.str.isupper()\n",
    "##        break\n",
    "##    inference[i].obj.str.isalpha()\n",
    "##    while True:\n",
    "##        inference[i].obj.str.isupper()\n",
    "##        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(result, columns=['MBTI'])\n",
    "result.to_csv(\"Final_result_team14.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
