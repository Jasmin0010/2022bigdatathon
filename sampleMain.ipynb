{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_size = 500\n",
    "epochs = 2\n",
    "mini_batch = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74357 entries, 0 to 74356\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   MBTI    74357 non-null  object\n",
      " 1   words   74357 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"MBTI_train.csv\", names=[\"MBTI\", \"words\"])\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INTP</td>\n",
       "      <td>say process model list like subscriber channel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>upon much manipulate retail finish like sacrif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>fit yes certain bff social feel goal go know n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>complete love within someone ideal joke solvea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>public strictly thing person x question person...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MBTI                                              words\n",
       "0  INTP  say process model list like subscriber channel...\n",
       "1  INFJ  upon much manipulate retail finish like sacrif...\n",
       "2  INFJ  fit yes certain bff social feel goal go know n...\n",
       "3  INTJ  complete love within someone ideal joke solvea...\n",
       "4  ENTJ  public strictly thing person x question person..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9337 entries, 0 to 9336\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   MBTI    0 non-null      object\n",
      " 1   words   9337 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 146.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_val_test = df_train.drop(df_train.index).copy()\n",
    "df_val = df_val_test.sample(frac=0.5, random_state=5).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = df_train['MBTI'].values\n",
    "data_train = df_train['words'].values\n",
    "\n",
    "labels_val = df_val['MBTI'].values\n",
    "data_val = df_val['words'].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "en_labels_train = le.fit_transform(labels_train)\n",
    "en_labels_val = le.transform(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Count of types')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_labels, count = np.unique(df_train['MBTI'], return_counts=True)\n",
    "fig = plt.figure(figsize=(9,5))\n",
    "plt.bar(unique_labels, count, width=0.8)\n",
    "plt.title(\"Count of types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_data(tokenizer, data2pad, maxlen):\n",
    "    sequence = tokenizer.texts_to_sequences(data2pad)\n",
    "    paded = pad_sequences(sequence, truncating='post', padding='post', maxlen=maxlen)\n",
    "    return paded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paded_data_train = pad_data(tokenizer, data_train, txt_size)\n",
    "paded_data_val = pad_data(tokenizer, data_val, txt_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74357, 500)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paded_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label): \n",
    "    text = tf.expand_dims(text, -1) \n",
    "    return vectorize_layer(text), label \n",
    "# Vectorize the data. \n",
    "\n",
    "max_features = 10000\n",
    "sequence_length = 500\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features, \n",
    "    output_mode=\"int\", \n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "vectorize_layer.adapt(data_train)\n",
    "vect_train = vectorize_layer(data_train)\n",
    "vect_val = vectorize_layer(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model1(post_size, num_labels):\n",
    "    model = Sequential([\n",
    "        layers.Embedding(10000, 32, input_length=post_size),\n",
    "        layers.Bidirectional(layers.LSTM(40, return_sequences=True)),\n",
    "        layers.Bidirectional(layers.LSTM(40)),\n",
    "        layers.Dense(num_labels, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def create_model2(post_size, num_labels):\n",
    "    inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "    \n",
    "    x = layers.Embedding(10000, 128)(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "    x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    predictions = layers.Dense(num_labels, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "    model = tf.keras.Model(inputs, predictions)\n",
    "    return model\n",
    "\n",
    "def show_history(h):\n",
    "    epochs_trained = len(h.history['loss'])\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('accuracy'), label='Training')\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('val_accuracy'), label='Validation')\n",
    "    plt.ylim([0., 1.])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('loss'), label='Training')\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('val_loss'), label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 32)           320000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 500, 80)          23360     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 80)               38720     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                1296      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 383,376\n",
      "Trainable params: 383,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1_token = create_model1(txt_size, len(unique_labels))\n",
    "model1_token.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1_token.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 128)         1280000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 128)         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 128)         114816    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 128)         114816    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 16)                2064      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,528,208\n",
      "Trainable params: 1,528,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2_token = create_model2(txt_size, len(unique_labels))\n",
    "model2_token.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model2_token.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 500, 32)           320000    \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 500, 80)          23360     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 80)               38720     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                1296      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 383,376\n",
      "Trainable params: 383,376\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1_vect = create_model1(txt_size, len(unique_labels))\n",
    "model1_vect.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model1_vect.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 128)         1280000   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 128)         0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, None, 128)         114816    \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, None, 128)         114816    \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 16)                2064      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,528,208\n",
      "Trainable params: 1,528,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2_vect = create_model2(txt_size, len(unique_labels))\n",
    "model2_vect.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model2_vect.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 68/149 [============>.................] - ETA: 1:37:47 - loss: 2.1028 - accuracy: 0.2341"
     ]
    }
   ],
   "source": [
    "h1_token = model1_token.fit(\n",
    "    paded_data_train, en_labels_train,\n",
    "    validation_data = (paded_data_val, en_labels_val),\n",
    "    epochs = epochs,\n",
    "    batch_size = mini_batch,\n",
    "    callbacks=[\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(h1_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_token = model2_token.fit(\n",
    "    paded_data_train, en_labels_train,\n",
    "    validation_data = (paded_data_val, en_labels_val),\n",
    "    epochs = epochs,\n",
    "    #batch_size = mini_batch,\n",
    "    callbacks=[\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(h2_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_vect = model1_vect.fit(\n",
    "    vect_train, en_labels_train,\n",
    "    validation_data = (vect_val, en_labels_val),\n",
    "    epochs = 35,\n",
    "    batch_size = mini_batch,\n",
    "    callbacks=[\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(h1_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_vect = model2_vect.fit(\n",
    "    vect_train, en_labels_train,\n",
    "    validation_data = (vect_val, en_labels_val),\n",
    "    epochs = epochs,\n",
    "    batch_size = mini_batch,\n",
    "    callbacks=[\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_history(h2_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch, label_batch = data_val.as_numpy_iterator().next()\n",
    "\n",
    "df_test = pd.read_csv(\"MBTI_test.csv\", names=[\"words\"])\n",
    "df_test['MBTI'] = np.nan\n",
    "df_test = df_test[['MBTI', 'words']]\n",
    "df_test = df_test.astype({'MBTI':'object'})\n",
    "df_test.info()\n",
    "\n",
    "inference = model1_token.predict_on_batch(df_test['words'])\n",
    "df_test['MBTI'] = inference\n",
    "\n",
    "labels_test = df_test['MBTI'].values\n",
    "data_test = df_test['words'].values\n",
    "en_labels_test = le.transform(labels_test)\n",
    "paded_data_test = pad_data(tokenizer, data_test, txt_size)\n",
    "vect_test = vectorize_layer(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference.obj.str.strip()\n",
    "inference.obj.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in inference:\n",
    "    inference[i].obj.str.isupper()\n",
    "    while True:\n",
    "        inference[i].obj.str.isupper()\n",
    "        break\n",
    "    inference[i].obj.str.isalpha()\n",
    "    while True:\n",
    "        inference[i].obj.str.isupper()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(inference, columns=['MBTI'])\n",
    "result.to_csv(\"Final_result_team14.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
